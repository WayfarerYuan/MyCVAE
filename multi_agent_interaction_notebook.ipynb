{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47572bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import struct\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b482a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Encoder(\n",
       "   (fc1): Linear(in_features=784, out_features=800, bias=True)\n",
       "   (fc2): Linear(in_features=800, out_features=400, bias=True)\n",
       "   (fc3): Linear(in_features=400, out_features=10, bias=True)\n",
       " ),\n",
       " Decoder(\n",
       "   (fc1): Linear(in_features=10, out_features=800, bias=True)\n",
       "   (fc2): Linear(in_features=800, out_features=400, bias=True)\n",
       "   (fc3): Linear(in_features=400, out_features=784, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model structures from the notebook\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, categorical_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.fc2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
    "        self.fc3 = nn.Linear(hidden_dim_2, categorical_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, categorical_dim, hidden_dim_1, hidden_dim_2, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(categorical_dim, hidden_dim_2)\n",
    "        self.fc2 = nn.Linear(hidden_dim_2, hidden_dim_1)\n",
    "        self.fc3 = nn.Linear(hidden_dim_1, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Ensure output is within [0,1]\n",
    "        return x\n",
    "\n",
    "def gumbel_softmax(logits, temperature):\n",
    "    gs = F.gumbel_softmax(logits, tau=temperature, hard=False, dim=-1)\n",
    "    return gs\n",
    "\n",
    "# Given the typical input size for MNIST and FashionMNIST is 28x28\n",
    "input_dim = 28 * 28\n",
    "hidden_dim_1 = 800\n",
    "hidden_dim_2 = 400\n",
    "categorical_dim = 10  # Assuming 10 categories for simplicity\n",
    "\n",
    "encoder = Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim)\n",
    "decoder = Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim)\n",
    "\n",
    "# Check if GPU is available and move the models to GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "encoder, decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3dd11a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "batch_size = 16\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load a batch for testing\n",
    "sample_batch, _ = next(iter(train_loader))\n",
    "sample_batch = sample_batch.to(device)\n",
    "\n",
    "sample_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de5e08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10]), torch.Size([1, 784]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the sender and receiver for the signalling game\n",
    "\n",
    "def sender(image):\n",
    "    \"\"\"\n",
    "    Encodes the input image into a signal.\n",
    "    \"\"\"\n",
    "    logits = encoder(image)\n",
    "    signal = gumbel_softmax(logits, temperature=1.0)  # Using a fixed temperature for now\n",
    "    return signal\n",
    "\n",
    "def receiver(signal):\n",
    "    \"\"\"\n",
    "    Decodes the signal into a predicted image.\n",
    "    \"\"\"\n",
    "    predicted_image = decoder(signal)\n",
    "    return predicted_image\n",
    "\n",
    "# Testing the sender and receiver functions\n",
    "sample_image = torch.rand((1, input_dim)).to(device)\n",
    "signal = sender(sample_image)\n",
    "predicted_image = receiver(signal)\n",
    "\n",
    "signal.shape, predicted_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc53bf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(543.6912, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the loss function for the signalling game\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = F.binary_cross_entropy()\n",
    "\n",
    "def signalling_game_loss(original_image, decoded_image):\n",
    "    \"\"\"\n",
    "    Computes the loss based on the difference between the original image and the decoded image.\n",
    "    \"\"\"\n",
    "    return criterion(original_image, decoded_image)\n",
    "\n",
    "def signalling_game_loss_batch(original_images, decoded_images):\n",
    "    \"\"\"\n",
    "    Computes the loss based on the difference between the original image and the decoded image.\n",
    "    \"\"\"\n",
    "    return F.binary_cross_entropy(decoded_images, original_images, reduction='sum') / original_images.shape[0]\n",
    "\n",
    "# Testing the loss function with a sample\n",
    "loss_sample = signalling_game_loss_batch(sample_image, predicted_image)\n",
    "loss_sample\n",
    "# signals = sender(sample_batch)\n",
    "# decoded_images = receiver(signals)\n",
    "# loss_sample_fixed = signalling_game_loss(sample_batch, decoded_images)\n",
    "# loss_sample_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452860e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 207.8253259\n",
      "Epoch [2/3], Loss: 206.5488210\n",
      "Epoch [3/3], Loss: 171.0368793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[207.82532585042318, 206.54882097167967, 171.03687932128906]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters and optimizer\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)\n",
    "\n",
    "# Training loop for the signalling game\n",
    "num_epochs = 3\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch, _ in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Sender encodes the image\n",
    "        signal = sender(batch)\n",
    "        \n",
    "        # Receiver decodes the signal\n",
    "        decoded_image = receiver(signal)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = signalling_game_loss_batch(batch, decoded_image)\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    average_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(average_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.7f}\")\n",
    "\n",
    "losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7b275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch.nn import functional as F\n",
    "# import struct\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import random\n",
    "\n",
    "# # Encoder, Decoder and other utility functions from previous implementations\n",
    "# ...  # (Code truncated for brevity)\n",
    "\n",
    "# # Multi-agent interaction and evolution\n",
    "\n",
    "# # Initialize multiple senders and receivers\n",
    "# num_senders = 3\n",
    "# num_receivers = 3\n",
    "\n",
    "# senders = [Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device) for _ in range(num_senders)]\n",
    "# receivers = [Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device) for _ in range(num_receivers)]\n",
    "\n",
    "# # Parameters for the multi-agent interaction\n",
    "# num_generations_multi = 5\n",
    "# num_interactions_multi = 100\n",
    "\n",
    "# # Main loop for generations with multiple senders and receivers\n",
    "# ...\n",
    "\n",
    "# import random\n",
    "\n",
    "# # Parameters for the multi-agent interaction\n",
    "# num_generations_multi = 5\n",
    "# num_interactions_multi = 100\n",
    "\n",
    "# # Track the performance over generations for multi-agent interactions\n",
    "# performance_over_generations_multi = []\n",
    "\n",
    "# # Main loop for generations with multiple senders and receivers\n",
    "# for generation in range(num_generations_multi):\n",
    "#     successful_interactions = 0\n",
    "    \n",
    "#     # Dynamic interactions within a generation\n",
    "#     for interaction in range(num_interactions_multi):\n",
    "#         # Randomly select a sender and a receiver\n",
    "#         selected_sender = random.choice(senders)\n",
    "#         selected_receiver = random.choice(receivers)\n",
    "        \n",
    "#         # Sample a random image\n",
    "#         sample_image, _ = next(iter(train_loader))\n",
    "#         sample_image = sample_image[0].to(device)\n",
    "        \n",
    "#         # Sender encodes the image\n",
    "#         signal = selected_sender(sample_image.unsqueeze(0))\n",
    "        \n",
    "#         # Receiver decodes the signal\n",
    "#         decoded_image = selected_receiver(signal)\n",
    "        \n",
    "#         # Check if the communication was successful\n",
    "#         loss = signalling_game_loss(sample_image, decoded_image)\n",
    "#         if loss < 0.1:  # Using a threshold to determine success\n",
    "#             successful_interactions += 1\n",
    "            \n",
    "#         # Update the selected sender and receiver based on the result\n",
    "#         optimizer_selected = optim.Adam(list(selected_sender.parameters()) + list(selected_receiver.parameters()), lr=learning_rate)\n",
    "#         optimizer_selected.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer_selected.step()\n",
    "    \n",
    "#     # Store the performance for this generation\n",
    "#     success_rate = successful_interactions / num_interactions_multi\n",
    "#     performance_over_generations_multi.append(success_rate)\n",
    "#     print(f\"Generation {generation + 1}, Success Rate: {success_rate:.4f}\")\n",
    "\n",
    "# performance_over_generations_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa84642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Initialize a small population of agents\n",
    "# initial_population = 2\n",
    "\n",
    "# senders_population = [Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device) for _ in range(initial_population)]\n",
    "# receivers_population = [Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device) for _ in range(initial_population)]\n",
    "\n",
    "# # Growth rule: for simplicity, add one sender and one receiver at the end of each generation\n",
    "# def grow_population(senders, receivers):\n",
    "#     # New sender inherits strategy from a random existing sender with potential small mutation (omitted for simplicity here)\n",
    "#     new_sender = Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device)\n",
    "#     new_sender.load_state_dict(random.choice(senders).state_dict())\n",
    "    \n",
    "#     # New receiver inherits strategy from a random existing receiver with potential small mutation (omitted for simplicity here)\n",
    "#     new_receiver = Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device)\n",
    "#     new_receiver.load_state_dict(random.choice(receivers).state_dict())\n",
    "    \n",
    "#     senders.append(new_sender)\n",
    "#     receivers.append(new_receiver)\n",
    "\n",
    "# # Check the initial population size\n",
    "# len(senders_population), len(receivers_population)\n",
    "\n",
    "# Modifying the growth rule to follow an exponential growth pattern\n",
    "\n",
    "# Initialize a small population of agents\n",
    "initial_population = 2\n",
    "\n",
    "senders_population = [Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device) for _ in range(initial_population)]\n",
    "receivers_population = [Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device) for _ in range(initial_population)]\n",
    "\n",
    "# Growth rule: for simplicity, double the population at the end of each generation (exponential growth)\n",
    "def grow_population(senders, receivers):\n",
    "    current_population = len(senders)\n",
    "    for _ in range(current_population):  # Double the current population\n",
    "        # New sender inherits strategy from a random existing sender with potential small mutation (omitted for simplicity here)\n",
    "        new_sender = Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device)\n",
    "        new_sender.load_state_dict(random.choice(senders).state_dict())\n",
    "        \n",
    "        # New receiver inherits strategy from a random existing receiver with potential small mutation (omitted for simplicity here)\n",
    "        new_receiver = Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device)\n",
    "        new_receiver.load_state_dict(random.choice(receivers).state_dict())\n",
    "        \n",
    "        senders.append(new_sender)\n",
    "        receivers.append(new_receiver)\n",
    "\n",
    "# Check the initial population size\n",
    "initial_population_sizes = (len(senders_population), len(receivers_population))\n",
    "initial_population_sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3674bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dynamic population interaction and evolution\n",
    "\n",
    "# # Parameters for the dynamic population interaction\n",
    "# num_generations_dynamic = 13\n",
    "# num_interactions_dynamic = 1000\n",
    "# learning_rate = 1e-3\n",
    "\n",
    "# # Track the performance and population size over generations for dynamic population interaction\n",
    "# performance_over_generations_dynamic = []\n",
    "# population_size_over_generations = []\n",
    "\n",
    "# # Main loop for generations with dynamic population growth\n",
    "# for generation in range(num_generations_dynamic):\n",
    "#     successful_interactions = 0\n",
    "    \n",
    "#     # Dynamic interactions within a generation\n",
    "#     for interaction in range(num_interactions_dynamic):\n",
    "#         # Randomly select a sender and a receiver from the current population\n",
    "#         selected_sender = random.choice(senders_population)\n",
    "#         selected_receiver = random.choice(receivers_population)\n",
    "        \n",
    "#         # Sample a random image\n",
    "#         sample_image, _ = next(iter(train_loader))\n",
    "#         sample_image = sample_image[0].to(device)\n",
    "        \n",
    "#         # Sender encodes the image\n",
    "#         # signal = selected_sender(sample_image.unsqueeze(0))\n",
    "#         signal = selected_sender(sample_image)\n",
    "        \n",
    "#         # Receiver decodes the signal\n",
    "#         decoded_image = selected_receiver(signal)\n",
    "        \n",
    "#         # Check if the communication was successful\n",
    "#         loss = signalling_game_loss_batch(sample_image, decoded_image)\n",
    "#         if loss < 0.1:  # Using a threshold to determine success\n",
    "#             successful_interactions += 1\n",
    "            \n",
    "#         # Update the selected sender and receiver based on the result\n",
    "#         optimizer_selected = optim.Adam(list(selected_sender.parameters()) + list(selected_receiver.parameters()), lr=learning_rate)\n",
    "#         optimizer_selected.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer_selected.step()\n",
    "    \n",
    "#     # Store the performance for this generation\n",
    "#     success_rate = successful_interactions / num_interactions_dynamic\n",
    "#     performance_over_generations_dynamic.append(success_rate)\n",
    "    \n",
    "#     # Track the population size\n",
    "#     population_size = len(senders_population)  # or len(receivers_population), they are the same\n",
    "#     population_size_over_generations.append(population_size)\n",
    "#     print(f\"Generation {generation + 1}, Success Rate: {success_rate:.4f}, Population Size: {population_size}\")\n",
    "\n",
    "#     # Apply the growth rule to increase the population\n",
    "#     if generation % 10 == 0:\n",
    "#         grow_population(senders_population, receivers_population)\n",
    "\n",
    "# performance_over_generations_dynamic, population_size_over_generations\n",
    "\n",
    "# # Plot the performance over generations\n",
    "# plt.plot(performance_over_generations_dynamic)\n",
    "# plt.xlabel(\"Generation\")\n",
    "# plt.ylabel(\"Success Rate\")\n",
    "# plt.title(\"Performance over Generations\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ba0f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 0 successful_interactions: 0, agents_population: 2\n",
      "generation 1 successful_interactions: 0, agents_population: 4\n",
      "generation 2 successful_interactions: 0, agents_population: 6\n",
      "generation 3 successful_interactions: 0, agents_population: 10\n",
      "generation 4 successful_interactions: 0, agents_population: 16\n",
      "generation 5 successful_interactions: 0, agents_population: 26\n",
      "generation 6 successful_interactions: 0, agents_population: 42\n",
      "generation 7 successful_interactions: 0, agents_population: 68\n",
      "generation 8 successful_interactions: 0, agents_population: 110\n",
      "generation 9 successful_interactions: 0, agents_population: 178\n",
      "generation 10 successful_interactions: 2, agents_population: 288\n",
      "generation 11 successful_interactions: 483, agents_population: 466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.4196670538133953e-05,\n",
       "  0.002228990724075869],\n",
       " [2, 4, 6, 10, 16, 26, 42, 68, 110, 178, 288, 466])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a class for Agent which can act both as a sender and a receiver\n",
    "class Agent:\n",
    "    def __init__(self, encoder_model, decoder_model, lifespan=3):\n",
    "        self.encoder = encoder_model\n",
    "        self.decoder = decoder_model\n",
    "        self.lifespan = lifespan\n",
    "\n",
    "# Parameters for the dynamic population interaction\n",
    "num_generations = 12\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Initialize agents\n",
    "initial_population = 2\n",
    "agents_population = [Agent(Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device),\n",
    "                               Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device)) \n",
    "                     for _ in range(initial_population)]\n",
    "\n",
    "# Modified growth function\n",
    "def grow_population_exponential(agents):\n",
    "    current_population = len(agents)\n",
    "    for _ in range(current_population):  # Double the current population\n",
    "        # New agent\n",
    "        new_agent = Agent(Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device),\n",
    "                              Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device))\n",
    "        agents.append(new_agent)\n",
    "\n",
    "# Modified interaction loop with a check for agent population size\n",
    "performance_over_generations_dynamic = []\n",
    "population_size_over_generations = []\n",
    "\n",
    "for generation in range(num_generations):\n",
    "    successful_interactions = 0\n",
    "    \n",
    "    # If there are less than 2 agents, skip the generation\n",
    "    if len(agents_population) < 2:\n",
    "        performance_over_generations_dynamic.append(0)  # No successful interactions\n",
    "        population_size_over_generations.append(len(agents_population))\n",
    "        continue\n",
    "    \n",
    "    # Every two agents interact once\n",
    "    for i, agent1 in enumerate(agents_population):\n",
    "        for j, agent2 in enumerate(agents_population):\n",
    "            if i != j:  # An agent doesn't interact with itself\n",
    "                # Sample a random image\n",
    "                sample_image, _ = next(iter(train_loader))\n",
    "                sample_image = sample_image[0].to(device)\n",
    "                \n",
    "                # Agent1 encodes the image\n",
    "                signal = agent1.encoder(sample_image)\n",
    "                \n",
    "                # Agent2 decodes the signal\n",
    "                decoded_image = agent2.decoder(signal)\n",
    "                \n",
    "                # Check if the communication was successful\n",
    "                loss = signalling_game_loss_batch(sample_image, decoded_image)\n",
    "                if loss < 0.1:\n",
    "                    successful_interactions += 1\n",
    "                \n",
    "                # Update the agents based on the result\n",
    "                optimizer_selected = optim.Adam(list(agent1.encoder.parameters()) + list(agent2.decoder.parameters()), lr=learning_rate)\n",
    "                optimizer_selected.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_selected.step()\n",
    "\n",
    "    # Reduce lifespan and remove agents if lifespan is 0\n",
    "    for agent in agents_population:\n",
    "        agent.lifespan -= 1\n",
    "    agents_population[:] = [agent for agent in agents_population if agent.lifespan > 0]\n",
    "    \n",
    "    # Store the performance for this generation\n",
    "    print(f'generation {generation} successful_interactions: {successful_interactions}, agents_population: {len(agents_population)}')\n",
    "    success_rate = successful_interactions / (len(agents_population) * (len(agents_population) - 1))  # (n * (n-1)) possible interactions\n",
    "    performance_over_generations_dynamic.append(success_rate)\n",
    "    \n",
    "    # Track the population size\n",
    "    population_size = len(agents_population)\n",
    "    population_size_over_generations.append(population_size)\n",
    "    \n",
    "    # Apply the growth rule every 10 generations\n",
    "    grow_population_exponential(agents_population)\n",
    "\n",
    "performance_over_generations_dynamic, population_size_over_generations\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myCVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
