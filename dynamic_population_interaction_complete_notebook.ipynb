{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04331717",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import struct\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Constants for the models\n",
    "input_dim = 28 * 28\n",
    "hidden_dim_1 = 256\n",
    "hidden_dim_2 = 128\n",
    "categorical_dim = 10  # Number of categories in the categorical distribution (One for each digit)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Encoder model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, categorical_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.fc2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
    "        self.fc3 = nn.Linear(hidden_dim_2, categorical_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, input_dim)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Define the Decoder model\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, categorical_dim, hidden_dim_2, hidden_dim_1, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(categorical_dim, hidden_dim_2)\n",
    "        self.fc2 = nn.Linear(hidden_dim_2, hidden_dim_1)\n",
    "        self.fc3 = nn.Linear(hidden_dim_1, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "\n",
    "# Signalling game loss\n",
    "def signalling_game_loss(original_image, decoded_image):\n",
    "    return F.mse_loss(decoded_image, original_image)\n",
    "\n",
    "# Growth rule\n",
    "def grow_population(senders, receivers):\n",
    "    # New sender inherits strategy from a random existing sender with potential small mutation (omitted for simplicity here)\n",
    "    new_sender = Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device)\n",
    "    new_sender.load_state_dict(random.choice(senders).state_dict())\n",
    "    \n",
    "    # New receiver inherits strategy from a random existing receiver with potential small mutation (omitted for simplicity here)\n",
    "    new_receiver = Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device)\n",
    "    new_receiver.load_state_dict(random.choice(receivers).state_dict())\n",
    "    \n",
    "    senders.append(new_sender)\n",
    "    receivers.append(new_receiver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f37f91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader_manual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m selected_receiver \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(receivers_population)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Sample a random image\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m sample_image, _ \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader_manual))\n\u001b[1;32m     28\u001b[0m sample_image \u001b[39m=\u001b[39m sample_image[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Sender encodes the image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader_manual' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dynamic population interaction and evolution\n",
    "\n",
    "# Constants for the dynamic interaction\n",
    "initial_population = 3\n",
    "num_generations_dynamic = 5\n",
    "num_interactions_dynamic = 100\n",
    "\n",
    "# Initialize a small population of agents\n",
    "senders_population = [Encoder(input_dim, hidden_dim_1, hidden_dim_2, categorical_dim).to(device) for _ in range(initial_population)]\n",
    "receivers_population = [Decoder(categorical_dim, hidden_dim_2, hidden_dim_1, input_dim).to(device) for _ in range(initial_population)]\n",
    "\n",
    "# Reset the performance and population size tracking\n",
    "performance_over_generations_dynamic = []\n",
    "population_size_over_generations = []\n",
    "\n",
    "# Main loop for generations with dynamic population growth\n",
    "for generation in range(num_generations_dynamic):\n",
    "    successful_interactions = 0\n",
    "    \n",
    "    # Dynamic interactions within a generation\n",
    "    for interaction in range(num_interactions_dynamic):\n",
    "        # Randomly select a sender and a receiver from the current population\n",
    "        selected_sender = random.choice(senders_population)\n",
    "        selected_receiver = random.choice(receivers_population)\n",
    "\n",
    "        train_dataset = \n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "        # Sample a random image\n",
    "        sample_image, _ = next(iter(train_loader_manual))\n",
    "        sample_image = sample_image[0].to(device)\n",
    "        \n",
    "        # Sender encodes the image\n",
    "        signal = selected_sender(sample_image.unsqueeze(0))\n",
    "        \n",
    "        # Receiver decodes the signal\n",
    "        decoded_image = selected_receiver(signal)\n",
    "        \n",
    "        # Check if the communication was successful\n",
    "        loss = signalling_game_loss(sample_image, decoded_image)\n",
    "        if loss < 0.1:  # Using a threshold to determine success\n",
    "            successful_interactions += 1\n",
    "            \n",
    "        # Update the selected sender and receiver based on the result\n",
    "        optimizer_selected = optim.Adam(list(selected_sender.parameters()) + list(selected_receiver.parameters()), lr=learning_rate)\n",
    "        optimizer_selected.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_selected.step()\n",
    "    \n",
    "    # Store the performance for this generation\n",
    "    success_rate = successful_interactions / num_interactions_dynamic\n",
    "    performance_over_generations_dynamic.append(success_rate)\n",
    "    \n",
    "    # Apply the growth rule to increase the population\n",
    "    grow_population(senders_population, receivers_population)\n",
    "    \n",
    "    # Track the population size\n",
    "    population_size = len(senders_population)  # or len(receivers_population), they are the same\n",
    "    population_size_over_generations.append(population_size)\n",
    "    print(f\"Generation {generation + 1}, Success Rate: {success_rate:.4f}, Population Size: {population_size}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myCVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
